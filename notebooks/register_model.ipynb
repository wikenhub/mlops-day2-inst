{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, boto3, botocore\n",
    "from datetime import datetime\n",
    "\n",
    "# --- Env (from mlops-env.sh) ---\n",
    "REGION   = os.environ.get(\"AWS_REGION\", \"ap-northeast-2\")\n",
    "BUCKET   = os.environ[\"BUCKET\"]\n",
    "LABP     = os.environ.get(\"LAB_PREFIX\", \"student\")\n",
    "SM_ROLE  = os.environ[\"SM_ROLE_ARN\"]\n",
    "S3_ARTIFACTS  = os.environ[\"S3_ARTIFACTS\"]\n",
    "\n",
    "boto_sess = boto3.Session(region_name=REGION)\n",
    "sm = boto_sess.client(\"sagemaker\")\n",
    "s3 = boto_sess.client(\"s3\")\n",
    "\n",
    "print(\"Region:\", REGION)\n",
    "print(\"Role:\", SM_ROLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the newest artifacts/evaluation/<job_name>/evaluation.json\n",
    "candidate_prefixes = [\n",
    "    \"artifacts/evaluation/\",           # canonical layout from Lab 6\n",
    "    f\"{LABP}/artifacts/evaluation/\",   # tolerate older/alternate layout\n",
    "]\n",
    "\n",
    "candidates = []\n",
    "paginator = s3.get_paginator(\"list_objects_v2\")\n",
    "for pref in candidate_prefixes:\n",
    "    for page in paginator.paginate(Bucket=BUCKET, Prefix=pref):\n",
    "        for obj in page.get(\"Contents\", []):\n",
    "            k = obj[\"Key\"]\n",
    "            if k.endswith(\"/evaluation.json\"):\n",
    "                candidates.append((obj[\"LastModified\"], k))\n",
    "\n",
    "if not candidates:\n",
    "    raise SystemExit(\"No evaluation.json found under artifacts/evaluation/. Run Lab 6 first.\")\n",
    "\n",
    "# Pick the most recent evaluation.json by LastModified\n",
    "last_modified, latest_key = max(candidates, key=lambda x: x[0])\n",
    "print(\"Latest evaluation.json:\", latest_key, \"| LastModified:\", last_modified)\n",
    "\n",
    "# Optional: derive job_name (artifacts/evaluation/<job_name>/evaluation.json)\n",
    "job_name = latest_key.rstrip(\"/\").split(\"/\")[-2]\n",
    "print(\"Detected job_name:\", job_name)\n",
    "\n",
    "obj = s3.get_object(Bucket=BUCKET, Key=latest_key)\n",
    "evaluation = json.loads(obj[\"Body\"].read())\n",
    "print(json.dumps(evaluation, indent=2)[:500], \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 4.a — Pick the serving image (framework container) for inference ---\n",
    "from sagemaker import image_uris\n",
    "\n",
    "sklearn_image = image_uris.retrieve(\n",
    "    framework=\"sklearn\",\n",
    "    region=REGION,\n",
    "    version=\"1.2-1\",\n",
    "    image_scope=\"inference\",\n",
    "    py_version=\"py3\",\n",
    ")\n",
    "print(\"Serving image:\", sklearn_image)\n",
    "\n",
    "# --- Step 4.b — Gather model + metrics ---\n",
    "# Derive training job name from evaluation.json produced in Lab 6\n",
    "job_name = evaluation[\"job_name\"]\n",
    "\n",
    "# Find model.tar.gz S3 location from the training job\n",
    "desc = sm.describe_training_job(TrainingJobName=job_name)\n",
    "model_data_url = desc[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "print(\"Model artifact S3:\", model_data_url)\n",
    "\n",
    "# Pull test metrics from evaluation.json\n",
    "test_metrics = evaluation[\"test\"]\n",
    "pr_auc  = float(test_metrics[\"pr_auc\"])\n",
    "roc_auc = float(test_metrics[\"roc_auc\"])\n",
    "threshold_star = float(test_metrics[\"threshold_star\"])\n",
    "\n",
    "# --- Step 4.c — Create a new Model Package version in the Group (no explicit name) ---\n",
    "# Required inputs:\n",
    "#   MPG_NAME        -> your model package group name (string)\n",
    "#   sklearn_image   -> ECR image URI for sklearn serving\n",
    "#   model_data_url  -> S3 URI to model.tar.gz (from describe_training_job)\n",
    "#   S3_ARTIFACTS    -> e.g., s3://.../artifacts  (ensure this is set in env)\n",
    "#   job_name        -> evaluation[\"job_name\"]\n",
    "#   pr_auc, roc_auc -> floats parsed from evaluation.json\n",
    "\n",
    "# Point the metrics at the same evaluation.json you wrote in Lab 6\n",
    "eval_json_s3 = f\"{S3_ARTIFACTS.rstrip('/')}/evaluation/{job_name}/evaluation.json\"\n",
    "\n",
    "model_description = (\n",
    "    f\"Telco churn (LogReg). \"\n",
    "    f\"Test ROC AUC={roc_auc:.3f}, PR AUC={pr_auc:.3f}. \"\n",
    "    f\"Artifacts from job {job_name}.\"\n",
    ")\n",
    "\n",
    "create_resp = sm.create_model_package(\n",
    "    ModelPackageGroupName=MPG_NAME,            # only the group (let SM version)\n",
    "    ModelPackageDescription=model_description,\n",
    "    InferenceSpecification={\n",
    "        \"Containers\": [\n",
    "            {\n",
    "                \"Image\": sklearn_image,\n",
    "                \"ModelDataUrl\": model_data_url,\n",
    "            }\n",
    "        ],\n",
    "        \"SupportedContentTypes\": [\"text/csv\", \"application/json\"],\n",
    "        \"SupportedResponseMIMETypes\": [\"application/json\"],\n",
    "    },\n",
    "    ModelApprovalStatus=\"PendingManualApproval\",\n",
    "    ModelMetrics={\n",
    "        \"ModelQuality\": {\n",
    "            \"Statistics\": {\n",
    "                \"ContentType\": \"application/json\",\n",
    "                \"S3Uri\": eval_json_s3,\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    # IMPORTANT: Do NOT put Tags here — tags are not supported on versions.\n",
    ")\n",
    "\n",
    "model_package_arn = create_resp[\"ModelPackageArn\"]\n",
    "print(\"Created Model Package version:\", model_package_arn)\n",
    "\n",
    "# --- Step 4.d — (Optional) Approve immediately (or leave pending for manual gate) ---\n",
    "# If you want to auto-approve now, do it as a separate call:\n",
    "# sm.update_model_package(\n",
    "#     ModelPackageArn=model_package_arn,\n",
    "#     ModelApprovalStatus=\"Approved\",\n",
    "#     ApprovalDescription=f\"Auto-approved from Lab 7. pr_auc={pr_auc:.3f}, roc_auc={roc_auc:.3f}, t*={threshold_star:.2f}\",\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = sm.describe_model_package(ModelPackageName=model_package_arn)\n",
    "print(\"Approval:\", resp[\"ModelApprovalStatus\"])\n",
    "print(\"Eval metrics S3:\", resp[\"ModelMetrics\"][\"ModelQuality\"][\"Statistics\"][\"S3Uri\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_comment = (\n",
    "    f\"Approved based on Lab 6 metrics: ROC AUC={roc_auc:.3f}, \"\n",
    "    f\"PR AUC={pr_auc:.3f}, threshold*={threshold_star:.2f}. \"\n",
    "    \"Meets classroom acceptance criteria.\"\n",
    ")\n",
    "\n",
    "_ = sm.update_model_package(\n",
    "    ModelPackageArn=model_package_arn,\n",
    "    ModelApprovalStatus=\"Approved\",  # or \"Rejected\"\n",
    "    ApprovalDescription=review_comment,\n",
    ")\n",
    "\n",
    "print(\"✓ Set approval to Approved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = sm.describe_model_package(ModelPackageName=model_package_arn)\n",
    "print(\"Approval:\", resp[\"ModelApprovalStatus\"])\n",
    "print(\"Eval metrics S3:\", resp[\"ModelMetrics\"][\"ModelQuality\"][\"Statistics\"][\"S3Uri\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 6 — Verify & fetch the latest Approved package (fixed)\n",
    "\n",
    "def latest_model_package_arn(group_name: str, status: str = \"Approved\"):\n",
    "    \"\"\"Return (arn, created_time) of the newest model package with given status.\"\"\"\n",
    "    resp = sm.list_model_packages(\n",
    "        ModelPackageGroupName=group_name,\n",
    "        ModelApprovalStatus=status,     # \"Approved\" | \"Rejected\" | \"PendingManualApproval\"\n",
    "        SortBy=\"CreationTime\",\n",
    "        SortOrder=\"Descending\",\n",
    "        MaxResults=20,\n",
    "    )\n",
    "    pkgs = resp.get(\"ModelPackageSummaryList\", [])\n",
    "    if not pkgs:\n",
    "        return None, None\n",
    "    return pkgs[0][\"ModelPackageArn\"], pkgs[0][\"CreationTime\"]\n",
    "\n",
    "latest_approved_arn, created = latest_model_package_arn(MPG_NAME, \"Approved\")\n",
    "print(\"Latest Approved ARN:\", latest_approved_arn, \"| Created:\", created)\n",
    "\n",
    "if latest_approved_arn:\n",
    "    # NOTE: Describe uses ModelPackageName, even when you pass an ARN.\n",
    "    info = sm.describe_model_package(ModelPackageName=latest_approved_arn)\n",
    "    print(\"Approval:\", info[\"ModelApprovalStatus\"])\n",
    "    print(\"Container Image:\", info[\"InferenceSpecification\"][\"Containers\"][0][\"Image\"])\n",
    "    print(\"ModelDataUrl:\", info[\"InferenceSpecification\"][\"Containers\"][0][\"ModelDataUrl\"])\n",
    "    print(\"Eval JSON:\", info[\"ModelMetrics\"][\"ModelQuality\"][\"Statistics\"][\"S3Uri\"])\n",
    "else:\n",
    "    print(\"No Approved packages yet. Approve one in Step 5 and re-run this cell.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
